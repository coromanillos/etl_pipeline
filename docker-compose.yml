version: "3.8"

services:
  db:
    image: postgres:16
    container_name: postgres_db
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    healthcheck:
      test:
        ["CMD", "pg_isready", "-U", "${POSTGRES_USER}", "-d", "${POSTGRES_DB}"]
      interval: 2s
      timeout: 2s
      retries: 10
    # Uncomment below if you want to persist Postgres data
    # volumes:
    #   - postgres_data:/var/lib/postgresql/data

  airflow-init:
    image: apache/airflow:3.0.1-python3.10
    container_name: airflow_init
    depends_on:
      db:
        condition: service_healthy
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW_UID: 50000
      AIRFLOW_GID: 50000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
    entrypoint: >
      bash -c "
      airflow db upgrade &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
      "

  airflow-webserver:
    image: apache/airflow:3.0.1-python3.10
    container_name: airflow_webserver
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      db:
        condition: service_healthy
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW_UID: 50000
      AIRFLOW_GID: 50000
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
    command: webserver

  airflow-scheduler:
    image: apache/airflow:3.0.1-python3.10
    container_name: airflow_scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      db:
        condition: service_healthy
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW_UID: 50000
      AIRFLOW_GID: 50000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
    command: scheduler
# Uncomment to persist database data:
# volumes:
#   postgres_data:

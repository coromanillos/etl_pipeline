# Main docker-compose.yml - Production-ready base configuration

# Airflow common configuration template
x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: ./airflow/Dockerfile
  image: etl_pipeline_airflow:${VERSION:-latest}
  restart: unless-stopped
  env_file:
    - .env
  environment:
    AIRFLOW_HOME: /app
    AIRFLOW__CORE__DAGS_FOLDER: /app/airflow/dags
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
    PYTHONPATH: /app
  volumes:
    - ./airflow/dags:/app/airflow/dags
    - ./airflow/plugins:/app/airflow/plugins
    - ./config:/app/config:ro
    - ./config:/opt/airflow/config:ro
    - airflow_logs:/app/logs
    - airflow_plugins:/app/plugins
    - ./src:/app/src

  networks:
    - etl_net
  depends_on:
    db:
      condition: service_healthy

services:
  airflow-webserver:
    <<: *airflow-common
    container_name: airflow_webserver
    command: >
      bash -c "
        airflow db upgrade &&
        airflow webserver
      "
    ports:
      - "${AIRFLOW_WEBSERVER_PORT:-8080}:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname airflow_scheduler"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s


  db:
    container_name: postgres_db
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT:-5434}:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./db/dev-init:/docker-entrypoint-initdb.d:ro
    networks:
      - etl_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  redshift_sim:
    container_name: redshift_sim
    image: postgres:16-alpine
    restart: unless-stopped
    ports:
      - "${REDSHIFT_PORT:-5433}:5432"
    environment:
      POSTGRES_USER: ${REDSHIFT_USER}
      POSTGRES_PASSWORD: ${REDSHIFT_PASSWORD}
      POSTGRES_DB: ${REDSHIFT_DB}
    volumes:
      - redshift_data:/var/lib/postgresql/data
      - ./db/redshift-init:/docker-entrypoint-initdb.d:ro
      - ./sql/redshift:/app/sql:ro
    networks:
      - etl_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${REDSHIFT_USER} -d ${REDSHIFT_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  localstack:
    image: localstack/localstack:${LOCALSTACK_VERSION:-3}
    container_name: localstack
    restart: unless-stopped
    ports:
      - "${LOCALSTACK_PORT:-4566}:4566"
      - "${LOCALSTACK_EDGE_PORT:-4571}:4571"
    environment:
      SERVICES: s3,secretsmanager,ssm,logs
      DEFAULT_REGION: ${AWS_REGION}
      AWS_ACCESS_KEY_ID: ${LOCALSTACK_ACCESS_KEY}
      AWS_SECRET_ACCESS_KEY: ${LOCALSTACK_SECRET_KEY}
      DATA_DIR: /tmp/localstack/data
    volumes:
      - localstack_data:/tmp/localstack/data
      - /var/run/docker.sock:/var/run/docker.sock
      - ./localstack/init:/etc/localstack/init/ready.d:ro
    networks:
      - etl_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4566/_localstack/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  fluentbit:
    image: fluent/fluent-bit:${FLUENTBIT_VERSION:-2.2.2}
    container_name: fluentbit
    restart: unless-stopped
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./fluentbit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ./fluentbit/parsers.conf:/fluent-bit/etc/parsers.conf:ro
      - fluentbit_storage:/var/log/fluent-bit-storage
    networks:
      - etl_net
    tmpfs:
      - /tmp
    read_only: true
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:2020/api/v1/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    depends_on:
      airflow-webserver:
        condition: service_healthy
      airflow-scheduler:
        condition: service_healthy

volumes:
  pgdata:
  redshift_data:
  localstack_data:
  fluentbit_storage:
  airflow_logs:
  airflow_plugins:

networks:
  etl_net:
    driver: bridge

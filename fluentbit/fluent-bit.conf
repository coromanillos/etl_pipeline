[SERVICE]
    Flush            5
    Log_Level        info
    Parsers_File     parsers.conf
    HTTP_Server      On
    HTTP_Listen      0.0.0.0
    HTTP_Port        2020
    storage.path     /var/log/fluent-bit-storage
    storage.sync     normal
    storage.checksum on
    storage.backlog.mem_limit 100M

[INPUT]
    Name             tail
    Path             /var/lib/docker/containers/*/*.log
    Parser           docker
    Tag              docker.*
    Refresh_Interval  5
    DB               /var/log/fluent-bit-docker.db
    Mem_Buf_Limit    10MB
    Skip_Long_Lines  On

[FILTER]
    Name             modify
    Match            docker.*
    # You can differentiate Airflow logs inside docker.* by matching container names, labels, etc.
    # For example, if Airflow container name contains "airflow":
    # Use a lua filter or grep filter to add 'airflow' tag if needed.
    Add              pipeline airflow-etl
    Add              environment production

[OUTPUT]
    Name             s3
    Match            docker.*
    Bucket           your-s3-bucket-name
    Region           us-east-1
    total_file_size  5M
    upload_timeout   60s
    store_dir        /tmp/fluent-bit/s3
    # Use tag in path to separate logs (docker/airflow logs go to same prefix, can be further filtered if needed)
    s3_key_format    /logs/${TAG}/%Y/%m/%d/%H/%M/$UUID.gz
    compression      gzip
    tls              On
    retry_on_error   true

[OUTPUT]
    Name             stdout
    Match            *
